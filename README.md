# ðŸ“§ Spam Email Detection â€” Machine Learning Project

## ðŸ“Œ Overview
This project builds a machine learning model to automatically classify messages as **Spam** or **Ham (Not Spam)** using Natural Language Processing (NLP) techniques.

The model is trained using TF-IDF vectorization and a Multinomial Naive Bayes classifier, with hyperparameter tuning and cross-validation to ensure strong generalization performance.

---

## ðŸŽ¯ Objective
To develop a robust spam detection system that:
- Accurately detects spam messages
- Minimizes false positives
- Generalizes well to unseen data
- Can be reused for future predictions

---

## ðŸ“‚ Dataset
The dataset contains labeled SMS messages:
- `ham (0)` â†’ legitimate messages
- `spam (1)` â†’ unwanted/promotional messages

Class distribution:
- Ham: 4825
- Spam: 747

---

## ðŸ›  Project Pipeline

### 1ï¸âƒ£ Data Preprocessing
- Lowercasing text
- Removing punctuation
- Removing stopwords
- Stemming
- Feature engineering:
  - Message length
  - Number of digits
  - Number of exclamation marks

### 2ï¸âƒ£ Feature Extraction
- TF-IDF Vectorization (unigrams + bigrams)
- Additional numerical features converted to categorical bins

### 3ï¸âƒ£ Model
- Multinomial Naive Bayes
- Hyperparameter tuning using GridSearchCV

### 4ï¸âƒ£ Evaluation Metrics
- Accuracy
- Precision
- Recall
- F1-score
- 5-Fold Cross-Validation

---

## ðŸ“Š Model Performance


**Test Set Results:**
- Accuracy: 0.99
- Spam Precision: 0.97
- Spam Recall: 0.92
- Spam F1-score: 0.94

**Cross-Validation Results (5-Fold CV on Training Set):**
- F1 scores per fold: [0.906, 0.950, 0.918, 0.932, 0.956]
- Mean F1-score: 0.933

> The close performance between Cross-Validation and Test scores indicates that the model does **not overfit** and generalizes well to unseen data.
